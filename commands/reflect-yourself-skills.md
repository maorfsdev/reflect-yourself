---
name: /reflect-yourself-skills
description: Discover repeating patterns that could become reusable skills.
---

# /reflect-yourself-skills - Skill Discovery from Patterns

Analyze session history to discover repeating patterns that could become reusable skills or commands.

---

## Instructions for Agent

### Step 1: Pattern Analysis

Review the conversation and any available context to identify:

#### Repeating Request Types
Look for requests that share the same **intent**, even with different wording:
- "debug the API" / "fix the endpoint" / "check why requests are failing"
- "create a new component" / "add a UI element" / "build a form"
- "write tests for this" / "add test coverage" / "test this function"

#### Multi-Step Workflows
Identify workflows that follow a consistent pattern:
- File creation → configuration → testing
- Debug → identify → fix → verify
- Research → implement → document

#### Domain Knowledge Requirements
Note specialized knowledge that was needed:
- Database schemas and relationships
- API conventions and authentication
- Project-specific file structures

### Step 2: Candidate Evaluation

For each pattern, evaluate:

| Criterion | Question | Weight |
|-----------|----------|--------|
| Frequency | How often does this pattern occur? | High |
| Complexity | Does it require multiple steps or special knowledge? | Medium |
| Consistency | Is the workflow similar each time? | High |
| Teachability | Can it be documented clearly? | Medium |

**Score each candidate:**
- **High Confidence (3+ occurrences, consistent workflow)**
- **Medium Confidence (2 occurrences, similar pattern)**
- **Low Confidence (1 occurrence, but complex enough to document)**

### Step 3: Location Decision

For each skill candidate:

```
Is it codebase-specific?
├── YES → Project Skill (.cursor/skills/)
│         Examples: api-debugging, database-migrations, deploy-workflow
│
└── NO → Could other projects benefit?
          ├── YES → Personal Skill (~/.cursor/skills/)
          │         Examples: git-workflow, code-review, testing-patterns
          │
          └── NO → Probably a one-off, skip
```

### Step 4: Present Candidates

```markdown
## Skill Candidates Discovered

Analyzed current session. Found these patterns:

### 1. `api-debugging` (High Confidence)
**Intent:** Debug issues with API endpoints
**Evidence:** Multiple debugging sessions following similar pattern
**Workflow:**
1. Check server logs for errors
2. Verify request parameters
3. Test endpoint directly (curl/Postman)
4. Check database query results
5. Verify authentication/permissions

**Corrections captured:**
- "Always check the request headers first"
- "Log the full request body for debugging"

**Recommended location:** Project skill (`.cursor/skills/api-debugging/`)

---

### 2. `component-creation` (Medium Confidence)
**Intent:** Create new UI components following project patterns
**Evidence:** 3 component creation sessions
**Workflow:**
1. Create component file with boilerplate
2. Add styles (CSS/Tailwind/styled-components)
3. Write unit tests
4. Export from index file
5. Add to storybook (if applicable)

**Corrections captured:**
- "Always include prop types/interfaces"
- "Use the shared Button component, don't create new ones"

**Recommended location:** Project skill (`.cursor/skills/component-creation/`)

---

## Actions

For each candidate, I can:
- **Generate** - Create the skill with full SKILL.md
- **Draft** - Create a skeleton to fill in later
- **Skip** - Not useful enough to formalize
- **Merge** - Combine with existing skill

Which skills should I generate? (e.g., "1" or "all" or "1,2 as drafts")
```

### Step 5: Generate Skills

For approved candidates, create:

**Directory structure:**
```
.cursor/skills/skill-name/
├── SKILL.md           # Main skill file
└── (optional extras)
```

**SKILL.md template:**
```markdown
---
name: skill-name
description: [Third-person description with trigger terms. Use when...]
---

# [Skill Title]

## Quick Start
[Essential steps for common use case]

## Workflow
1. [Step 1]
2. [Step 2]
...

## Guardrails
- [Important constraint or best practice]
- [Common mistake to avoid]

## Corrections Log
- [Date]: [Learning from correction]

---
*Generated by /reflect-yourself-skills*
```

### Step 6: Summary

```markdown
## Skills Generated

### Created
- ✅ `api-debugging` → `.cursor/skills/api-debugging/`
- ✅ `component-creation` → `.cursor/skills/component-creation/`

### Skipped
- ⏭️ "quick-fixes" - not enough pattern consistency yet

### Recommendations
- Run `/reflect-yourself` after your next few sessions to capture more corrections
- Consider merging related skills if they overlap significantly
```

---

## Cross-Session Analysis

For deeper pattern analysis across multiple sessions, ask the user:

> "Would you like me to analyze patterns from previous conversations? 
> I can look at your existing skills and recent work to find:
> - Skills that need updating
> - Patterns that keep recurring  
> - Knowledge that should be formalized"

If approved, review:
1. Existing skills in `.cursor/skills/`
2. Recent files modified (from git or file history)
3. Any documented patterns in rules

---

## Integration with /reflect-yourself

- `/reflect-yourself` captures individual corrections → queues them
- `/reflect-yourself-skills` finds patterns → creates skills
- Both update existing skills when relevant

When a correction is captured during skill usage:
```
User runs: "Help me debug the API"
Agent uses: api-debugging skill
User corrects: "No, check the network tab first, not server logs"

→ /reflect-yourself routes this correction to the skill itself
→ api-debugging skill gets updated with new step
```
